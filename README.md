Explainable AI Dashboard

A Streamlit-based interactive dashboard for interpreting Machine Learning models using SHAP (SHapley Additive exPlanations).

ðŸ“Œ Features

	â€¢	Upload your own CSV datasets
	â€¢	Automatically detects classification or regression tasks
	â€¢	Trains a Random Forest model
	â€¢	Computes global feature importance with SHAP beeswarm plots
	â€¢	Visualizes local feature attribution using SHAP waterfall plots
	â€¢	Downloadable SHAP visualizations
	â€¢	Handles both numerical and categorical features

![image](https://github.com/user-attachments/assets/a93ed0c3-50c5-431f-b5a2-f6eeb8edfe81)
![image](https://github.com/user-attachments/assets/59db57e0-9895-467c-b372-bcc625122116)
![image](https://github.com/user-attachments/assets/b62a4d67-d8f6-4f5b-a22d-a3b088de8064)


ðŸš€ Getting Started

1. Clone the repository
   git clone https://github.com/YOUR_USERNAME/explainable-ai-dashboard.git
cd explainable-ai-dashboard
2. Create and activate a virtual environment (optional)
   python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
4. Install dependencies
   pip install -r requirements.txt
5. Run the app
   streamlit run app.py

 Sample Dataset

A sample dataset (sample_regression_data.csv) is provided for testing. It includes both categorical and numerical features for regression tasks.




ðŸ”§ Tech Stack
	â€¢	Python
	â€¢	Streamlit
	â€¢	SHAP
	â€¢	scikit-learn
	â€¢	Matplotlib

ðŸ“ˆ Future Features
	â€¢	Support for XGBoost, LightGBM, and CatBoost models
	â€¢	Upload pre-trained models
	â€¢	Display model performance metrics (accuracy, RMSE)
	â€¢	Compare multiple models
